<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us"><head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>Understanding NIC Utilization in VMware ESX - Howell Yang&#39;s Weblog - 我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。</title>

  
  <meta name="author" content="Howell Yang">
  <meta property="og:site_name" content="Scott&#39;s Weblog">
  
  <meta property="og:description" content="Understanding NIC Utilization in VMware ESX - Howell Yang&#39;s Weblog - 我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。">
  <meta property="og:title" content="Understanding NIC Utilization in VMware ESX - Howell Yang&#39;s Weblog - 我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。">
  
  <meta property="og:type" content="article">
  <meta name="keywords" content="Cloud, Containers, Kubernetes, K8s, Docker, CNI, CRI-O, OCI, Linux, CLI, Networking, AWS, Security, DevOps">

  
  <link rel="stylesheet" href="/css/poole.css">
  <link rel="stylesheet" href="/css/syntax.css">
  <link rel="stylesheet" href="/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">
  <link rel="stylesheet" href="/public/font-awesome/css/font-awesome.min.css">

  
  <link rel="canonical" href="https://www.howellyang.com/2008/07/16/understanding-nic-utilization-in-vmware-esx/">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/assets/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/assets/favicon.ico">

  
  </head>
<body class="theme-base-0d">
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">


<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p><img src="/public/img/orbits-thumb.gif" alt="Orbits" width="128" height="128" /></p>
    <p>Original, technical content centered around cloud computing, Kubernetes, Linux, and networking</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item " href="/">Home</a>
    <a class="sidebar-nav-item" href="/about/">About</a>
    <a class="sidebar-nav-item" href="/archives/">Site Archives</a>
    <a class="sidebar-nav-item" href="/categories/">Post Categories</a>
    <a class="sidebar-nav-item" href="/tags/">Content Tags</a>
  </nav>

  <div class="sidebar-item">
    <p>
      <a href="https://github.com/howellyang"><i class="fa fa-github fa-3x"></i></a>
      <a href="https://twitter.com/None"><i class="fa fa-twitter fa-3x"></i></a>
      <a href="https://www.linkedin.com/in/None"><i class="fa fa-linkedin-square fa-3x"></i></a>
      <a href="http://feeds.scottlowe.org/slowe/content/feed/"><i class="fa fa-rss fa-3x"></i></a>
    </p>
  </div>

  <div class="sidebar-item">
    <p>&copy; 2005-2022. All rights reserved.</p>
  </div>
</div>

    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Howell Yang&#39;s Weblog</a>
            <small>我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。</small>
          </h3>
        </div>
      </div>

      <div class="container content">
<div class="post">
  <h1 class="post-title">Understanding NIC Utilization in VMware ESX</h1>
  <span class="post-date"><i class="fa fa-calendar" aria-hidden="true"></i>&#160;Published on 169 May 161616 &middot;
    <i class="fa fa-folder-open-o" aria-hidden="true"></i>&#160;Filed in <a href="/categories/explanation">Explanation</a> &middot;
    <i class="fa fa-pencil" aria-hidden="true"></i>&#160;1165 words (estimated 6 minutes to read)</span>
  <p>In early December of 2006, I wrote a very popular article on <a href="/2006/12/04/esx-server-nic-teaming-and-vlan-trunking/">VMware ESX, NIC teaming, and VLAN trunking</a>. In that article, I laid out the configuration for using both NIC teaming and VLAN trunking. In particular, the NIC teaming configuration in that article described the use of Cisco Gigabit EtherChannel for link aggregation, in which both the physical switch and the vSwitch are configured to distribute traffic across all the links between them.</p>
<p>Since that time, the question has come up many times: which method is better, with EtherChannel or without? Many engineers prefer <em>not</em> to use EtherChannel (or its standardized equivalent, static LACP/802.3ad) because of the added complexity involved. It&rsquo;s easier to just team the NICs at the vSwitch level and leave the physical switches alone. That is true, but what about performance? And what impact does this have on NIC utilization?</p>
<p>There are two ways of handling NIC teaming in VMware ESX:</p>
<ol>
<li>
<p>Without any physical switch configuration</p>
</li>
<li>
<p>With physical switch configuration (EtherChannel, static LACP/802.3ad, or its equivalent)</p>
</li>
</ol>
<p>In the NIC teaming/VLAN trunking article I referenced above, I noted that there is a corresponding vSwitch configuration that matches each of these types of NIC teaming:</p>
<ol>
<li>
<p>For NIC teaming without physical switch configuration, the vSwitch must be set to either &ldquo;Route based on originating virtual port ID&rdquo;, &ldquo;Route based on source MAC hash&rdquo;, or &ldquo;Use explicit failover order&rdquo;</p>
</li>
<li>
<p>For NIC teaming with physical switch configuration&mdash;EtherChannel, static LACP/802.3ad, or its equivalent&mdash;the vSwitch must be set to &ldquo;Route based on ip hash&rdquo;</p>
</li>
</ol>
<p>In order to better understand how these settings and different configurations affect NIC utilization, I set out to do some tests in the lab. Most of my tests were centered around IP-based storage from the host (i.e., using NFS or iSCSI for VMDKs), and only tested two basic configurations: using &ldquo;Route based on originating virtual port ID&rdquo; and no link aggregation and using &ldquo;Route based on ip hash&rdquo; with link aggregation. Although the tests were slanted toward IP-based storage traffic, the underlying principles should be the same for other types of traffic as well. Here&rsquo;s what I found.</p>
<h2 id="nic-teaming-without-link-aggregation">NIC Teaming Without Link Aggregation</h2>
<p>First, it&rsquo;s important to understand the basic behavior in this configuration. Because the vSwitch is set to &ldquo;Route based on originating virtual port ID&rdquo;, network traffic will be placed onto a specific uplink and won&rsquo;t use any other uplinks until that uplink fails. (This is described in more detail in <a href="http://www.vmware.com/files/pdf/virtual_networking_concepts.pdf">this PDF</a> from VMware.) Every VM and every VMkernel port gets its own virtual port ID. These virtual port IDs are visible using esxtop (launch esxtop, then press &ldquo;n&rdquo; to switch to network statistics). That&rsquo;s simple enough, but what does this mean in practical terms?</p>
<ul>
<li>
<p>Each VM will only use a single network uplink, regardless of how many different connections that particular VM may be handling. All traffic to and from that VM will be place on that single uplink, regardless of how many uplinks are configured on the vSwitch.</p>
</li>
<li>
<p>Each VMkernel NIC will only use a single network uplink. This is true both for VMotion as well as IP-based storage traffic, and is true regardless of how many uplinks are configured on the vSwitch.</p>
</li>
<li>
<p>Even when the traffic patterns are such that using multiple uplinks would be helpful&mdash;for example, when a VM is copying data to or from two different network locations at the same time, or when a VMkernel NIC is accessing two different iSCSI targets&mdash;only a single uplink will be utilized.</p>
</li>
</ul>
<p>This last bullet is particularly important. Consider the implications in a VMware Infrastructure 3 (VI3) environment using the software iSCSI initiator with multiple iSCSI targets. Even though multiple iSCSI targets may be configured, <strong>all</strong> the iSCSI targets will share <strong>one</strong> uplink from that vSwitch using this configuration. Obviously, that is not ideal.</p>
<p>Note that this doesn&rsquo;t really impact VMotion traffic, since VMotion is a point-to-point type of connection. VMotion would only be impacted if placed on a vSwitch with other types of traffic and their virtual port IDs were assigned to the same uplink.</p>
<h2 id="nic-teaming-with-link-aggregation">NIC Teaming With Link Aggregation</h2>
<p>In this configuration, EtherChannel/static LACP/802.3ad is configured on the physical switch and the ESX vSwitch is configured for &ldquo;Route based on ip hash.&rdquo; With this configuration, the behavior changes quite dramatically.</p>
<ul>
<li>
<p>Traffic to or from a VM could be placed onto any uplink on the vSwitch, depending upon the source and destination IP addresses. Each pair of source and destination IP addresses could be placed on different uplinks, but any given pair of IP addresses can use only a single uplink. In other words, multiple connections to or from the VM will benefit, but each individual connection can only utilize a single link.</p>
</li>
<li>
<p>Each VMkernel NIC will utilize multiple uplinks only if multiple destination IP addresses are involved. Conceivably, you could also use multiple VMkernel NICs with multiple source IP addresses, but I haven&rsquo;t tested that configuration.</p>
</li>
<li>
<p>Traffic that is primarily point-to-point won&rsquo;t see any major benefit from this configuration. A single VM being accessed by another single client won&rsquo;t see a traffic boost other than that possibly gained by the placement of other traffic onto other uplinks.</p>
</li>
</ul>
<p>This configuration can help improve uplink utilization on a vSwitch because traffic is dynamically placed onto the uplinks based on the source and destination IP addresses. This helps improve overall NIC utilization when there are multiple VMs or when a VMkernel NIC is accessing multiple IP-based storage targets. Note again, though, that individual connections will only ever be able to utilize a single uplink.</p>
<h2 id="practical-application">Practical Application</h2>
<p>I come back again to the question I asked earlier: what does this mean in practical terms?</p>
<ul>
<li>
<p>If you want to scale IP-based storage traffic, you&rsquo;ll have to use link aggregation <strong>and</strong> multiple targets. Using link aggregation with a single target (destination IP address) won&rsquo;t use more than a single uplink; similarly, no link aggregation with multiple targets will still result in only a single uplink being used. Only with link aggregation <strong>and</strong> multiple targets will multiple uplinks get used.</p>
</li>
<li>
<p>Link aggregation will help with better overall uplink utilization for vSwitches hosting VMs. Because there are multiple source/destination address pairs in play, the vSwitch will spread them around the uplinks dynamically.</p>
</li>
<li>
<p>To achieve the best possible uplink utilization as well as provide redundancy, you&rsquo;ll need physical switches that support cross-stack link aggregation. I believe the Cisco Catalyst 3750 switches do, as do the Catalyst 3120 switches for the HP c-Class blade chassis. I don&rsquo;t know about other vendors, since I deal primarily with Cisco.</p>
</li>
</ul>
<p>Clearly, this has some implications for efficient and scalable VI3 designs. I&rsquo;d love to hear everyone&rsquo;s feedback on this matter. In my humble opinion, extended conversations about this topic can only serve to better educate the community as a whole.</p>
<p><strong>UPDATE:</strong> Reader Tim Washburn pointed out that the &ldquo;Route based on Source MAC hash&rdquo; actually can&rsquo;t be used in conjunction with link aggregation; it&rsquo;s behavior is identical to &ldquo;Route based on originating virtual port ID&rdquo;. Thanks for the correction, Tim!</p>


  <h3>Metadata and Navigation</h3>
  <span class="post-meta">
  <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/cisco">Cisco</a> <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/esx">ESX</a> <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/networking">Networking</a> <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/virtualization">Virtualization</a> <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/vmware">VMware</a> 

  <br />
  <i class="fa fa-arrow-circle-left" aria-hidden="true"></i> Previous Post: <a href="https://www.howellyang.com/2008/07/15/in-the-works/">In the Works</a>
  
  <br />
   <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> Next Post: <a href="https://www.howellyang.com/2008/07/16/im-honored-too/">I&#39;m Honored, Too</a>
  </span>

  <span class="post-sharing">
  <p>Be social and share this post!<br />

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.howellyang.com%2f2008%2f07%2f16%2funderstanding-nic-utilization-in-vmware-esx%2f" title="Share on Facebook"><i class="fa fa-facebook-square fa-2x"></i></a>
  <a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fwww.howellyang.com%2f2008%2f07%2f16%2funderstanding-nic-utilization-in-vmware-esx%2f&text=Understanding%20NIC%20Utilization%20in%20VMware%20ESX" title="Share on Twitter"><i class="fa fa-twitter-square fa-2x"></i></a>
  <a href="https://plus.google.com/share?url=https%3a%2f%2fwww.howellyang.com%2f2008%2f07%2f16%2funderstanding-nic-utilization-in-vmware-esx%2f" title="Share on Google Plus"><i class="fa fa-google-plus-square fa-2x"></i></a></p>
  </span>
</div>

<div class="related">
  <h3>Related Posts</h3>
  <ul class="related-posts">
  <li><a href="/2008/03/11/identifying-esx-server-nics-in-blades/">Identifying ESX Server NICs in Blades</a> <span class="post-date-list">119 May 111111</span></li><li><a href="/2008/03/07/configuration-for-protecting-vmotion/">Configuration for Protecting VMotion</a> <span class="post-date-list">79 May 7077</span></li><li><a href="/2006/12/04/esx-server-nic-teaming-and-vlan-trunking/">ESX Server, NIC Teaming, and VLAN Trunking</a> <span class="post-date-list">49 May 4044</span></li>
  </ul>
</div>      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

  </body>
</html>
