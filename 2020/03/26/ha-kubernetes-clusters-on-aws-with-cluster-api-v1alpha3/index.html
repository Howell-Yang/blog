<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en-us"><head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>HA Kubernetes Clusters on AWS with Cluster API v1alpha3 - Howell Yang&#39;s Weblog - 我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。</title>

  
  <meta name="author" content="Howell Yang">
  <meta property="og:site_name" content="Scott&#39;s Weblog">
  
  <meta property="og:description" content="HA Kubernetes Clusters on AWS with Cluster API v1alpha3 - Howell Yang&#39;s Weblog - 我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。">
  <meta property="og:title" content="HA Kubernetes Clusters on AWS with Cluster API v1alpha3 - Howell Yang&#39;s Weblog - 我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。">
  
  <meta property="og:type" content="article">
  <meta name="keywords" content="Cloud, Containers, Kubernetes, K8s, Docker, CNI, CRI-O, OCI, Linux, CLI, Networking, AWS, Security, DevOps">

  
  <link rel="stylesheet" href="/css/poole.css">
  <link rel="stylesheet" href="/css/syntax.css">
  <link rel="stylesheet" href="/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700|PT+Sans:400">
  <link rel="stylesheet" href="/public/font-awesome/css/font-awesome.min.css">

  
  <link rel="canonical" href="https://www.howellyang.com/2020/03/26/ha-kubernetes-clusters-on-aws-with-cluster-api-v1alpha3/">

  
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/assets/apple-touch-icon-144-precomposed.png">
  <link rel="shortcut icon" href="/assets/favicon.ico">

  
  </head>
<body class="theme-base-0d">
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">


<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p><img src="/public/img/orbits-thumb.gif" alt="Orbits" width="128" height="128" /></p>
    <p>Original, technical content centered around cloud computing, Kubernetes, Linux, and networking</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item " href="/">Home</a>
    <a class="sidebar-nav-item" href="/about/">About</a>
    <a class="sidebar-nav-item" href="/archives/">Site Archives</a>
    <a class="sidebar-nav-item" href="/categories/">Post Categories</a>
    <a class="sidebar-nav-item" href="/tags/">Content Tags</a>
  </nav>

  <div class="sidebar-item">
    <p>
      <a href="https://github.com/howellyang"><i class="fa fa-github fa-3x"></i></a>
      <a href="https://twitter.com/None"><i class="fa fa-twitter fa-3x"></i></a>
      <a href="https://www.linkedin.com/in/None"><i class="fa fa-linkedin-square fa-3x"></i></a>
      <a href="http://feeds.scottlowe.org/slowe/content/feed/"><i class="fa fa-rss fa-3x"></i></a>
    </p>
  </div>

  <div class="sidebar-item">
    <p>&copy; 2005-2022. All rights reserved.</p>
  </div>
</div>

    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Howell Yang&#39;s Weblog</a>
            <small>我是杨豪，专注于深度学习模型的训练、剪枝、量化、部署以及工程效率优化。欢迎来到我的博客。</small>
          </h3>
        </div>
      </div>

      <div class="container content">
<div class="post">
  <h1 class="post-title">HA Kubernetes Clusters on AWS with Cluster API v1alpha3</h1>
  <span class="post-date"><i class="fa fa-calendar" aria-hidden="true"></i>&#160;Published on 269 May 262626 &middot;
    <i class="fa fa-folder-open-o" aria-hidden="true"></i>&#160;Filed in <a href="/categories/explanation">Explanation</a> &middot;
    <i class="fa fa-pencil" aria-hidden="true"></i>&#160;996 words (estimated 5 minutes to read)</span>
  <p>A few weeks ago, I published a post on <a href="/2020/03/05/ha-kubernetes-clusters-on-aws-with-cluster-api-v1alpha2/">HA Kubernetes clusters on AWS with Cluster API v1alpha2</a>. That post was itself a follow-up to a post I wrote in September 2019 on <a href="/2019/09/05/highly-available-kubernetes-clusters-on-aws-with-cluster-api/">setting up HA clusters using Cluster API v1alpha1</a>. In this post, I&rsquo;ll follow up on both of those posts with a look at setting up HA Kubernetes clusters on AWS using <a href="https://cluster-api.sigs.k8s.io/">Cluster API</a> v1alpha3. Although this post is similar to the v1alpha2 post, be aware there are some notable changes in v1alpha3, particularly with regard to the control plane.</p>
<p>If you&rsquo;re not yet familiar with Cluster API, take a look at <a href="/2019/08/26/an-introduction-to-kubernetes-cluster-api/">this high-level overview</a> I wrote in August 2019. That post will provide an explanation of the project&rsquo;s goals as well as provide some terminology.</p>
<p>In this post, I won&rsquo;t discuss the process of establishing a management cluster; I&rsquo;m assuming your Cluster API management cluster is already up and running. (I do have some articles in the content pipeline that discuss creating a management cluster.) Instead, this post will focus on creating a highly-available workload cluster. By &ldquo;highly available,&rdquo; I mean a cluster with multiple control plane nodes that are distributed across multiple availability zones (AZs). Please read the &ldquo;Disclaimer&rdquo; section at the bottom for some caveats with regard to availability.</p>
<h2 id="prerequisites">Prerequisites</h2>
<p>As mentioned above, this post assumes you already have a functional Cluster API management cluster. This post also assumes you have already installed the <code>kubectl</code> binary, and that you&rsquo;ve configured <code>kubectl</code> to access your management cluster.</p>
<p>As a side note, I <em>highly</em> recommend some sort of solution that shows you the current Kubernetes context in your shell prompt. I prefer <a href="https://github.com/justjanne/powerline-go"><code>powerline-go</code></a>, but choose/use whatever works best for you.</p>
<h2 id="crafting-manifests-for-high-availability">Crafting Manifests for High Availability</h2>
<p>The Cluster API manifests require two basic changes in order to be able to deploy a highly-available cluster:</p>
<ol>
<li>The AWSCluster object needs to be modified to include information on how to create subnets across multiple AZs.</li>
<li>The manifests for worker nodes need to be modified to include AZ information.</li>
</ol>
<p>You&rsquo;ll note that I didn&rsquo;t mention anything about the control plane above&mdash;that&rsquo;s because v1alpha3 introduces a new mechanism for managing the control plane of workload clusters. This new mechanism, the KubeadmControlPlane object, is smart enough in this release to automatically distribute control plane nodes across multiple AZs when they are present. (Nice, right?)</p>
<p>The next two sections will provide more details on the changes listed above.</p>
<h3 id="creating-subnets-across-multiple-azs">Creating Subnets Across Multiple AZs</h3>
<p>By default, Cluster API will only create public and private subnets in the first AZ it finds in a region. As a result, all control plane nodes and worker nodes will end up in the same AZ. To change that, you&rsquo;ll need to modify the AWSCluster object to tell Cluster API to create subnets across multiple AZs.</p>
<p>This change is accomplished by adding a <code>networkSpec</code> to the AWSCluster specification. Here&rsquo;s an example <code>networkSpec</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">networkSpec</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">vpc</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cidrBlock</span>: <span style="color:#ae81ff">10.10.0.0</span><span style="color:#ae81ff">/16</span>
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">subnets</span>:
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">availabilityZone</span>: <span style="color:#ae81ff">us-west-2a</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cidrBlock</span>: <span style="color:#ae81ff">10.10.0.0</span><span style="color:#ae81ff">/20</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">isPublic</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">availabilityZone</span>: <span style="color:#ae81ff">us-west-2a</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cidrBlock</span>: <span style="color:#ae81ff">10.10.16.0</span><span style="color:#ae81ff">/20</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">availabilityZone</span>: <span style="color:#ae81ff">us-west-2b</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cidrBlock</span>: <span style="color:#ae81ff">10.10.32.0</span><span style="color:#ae81ff">/20</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">isPublic</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">availabilityZone</span>: <span style="color:#ae81ff">us-west-2b</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cidrBlock</span>: <span style="color:#ae81ff">10.10.48.0</span><span style="color:#ae81ff">/20</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">availabilityZone</span>: <span style="color:#ae81ff">us-west-2c</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cidrBlock</span>: <span style="color:#ae81ff">10.10.64.0</span><span style="color:#ae81ff">/20</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">isPublic</span>: <span style="color:#66d9ef">true</span>
</span></span><span style="display:flex;"><span>    - <span style="color:#f92672">availabilityZone</span>: <span style="color:#ae81ff">us-west-2c</span>
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">cidrBlock</span>: <span style="color:#ae81ff">10.10.80.0</span><span style="color:#ae81ff">/20</span>
</span></span></code></pre></div><p>This YAML is fairly straightforward, and is largely (completely?) unchanged from previous versions of Cluster API. One key takeaway is that the user is responsible for &ldquo;manually&rdquo; breaking down the VPC CIDR appropriately for the subnets in each AZ.</p>
<p>With this change, Cluster API will now create multiple subnets within a VPC, distributing those subnets across AZs as directed. Since multiple AZs are now accessible by Cluster API, the control plane nodes (managed by the KubeadmControlPlane object) will automatically get distributed across AZs. This leaves only the worker nodes to distribute, which I&rsquo;ll discuss in the next section.</p>
<h3 id="distributing-worker-nodes-across-azs">Distributing Worker Nodes Across AZs</h3>
<p>To distribute worker nodes across AZs, users can add a <code>failureDomain</code> field to their Machine or MachineDeployment manifests. This field specifies the name of an AZ where a usable subnet exists. Using the example AWSCluster specification listed above, this means I could tell Cluster API to use us-west-2a, us-west-2b, or us-west-2c. I could <em>not</em> tell Cluster API to use us-west-2d, because there are no Cluster API-usable subnets in that AZ.</p>
<p>For a Machine object, the <code>failureDomain</code> field goes in the Machine&rsquo;s specification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">failureDomain</span>: <span style="color:#e6db74">&#34;us-west-2a&#34;</span>
</span></span></code></pre></div><p>For a MachineDeployment, the <code>failureDomain</code> field goes in the template specification:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-yaml" data-lang="yaml"><span style="display:flex;"><span><span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">template</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">spec</span>:
</span></span><span style="display:flex;"><span>      <span style="color:#f92672">failureDomain</span>: <span style="color:#e6db74">&#34;us-west-2b&#34;</span>
</span></span></code></pre></div><p>Given the nature of a MachineDeployment, it&rsquo;s not possible to distribute Machines from a single MachineDeployment across AZs. To use MachineDeployments with multiple AZs, you&rsquo;d need to use a separate MachineDeployment for each AZ.</p>
<p>With these two changes&mdash;adding a <code>networkSpec</code> to the AWSCluster object and adding a <code>failureDomain</code> field to your Machine or MachineDeployment objects&mdash;Cluster API will instantiate a Kubernetes cluster whose control plane nodes and worker nodes are distributed across multiple AWS AZs.</p>
<h2 id="disclaimer">Disclaimer</h2>
<p>Readers should note that deploying across multiple AZs is not a panacea to cure all availability ills. Although the loss of a single AZ will not (generally) render the cluster unavailable&mdash;etcd will maintain a quorum so the API server will continue to function&mdash;the control plane may be flooded with the demands of rescheduling Pods, and remaining active nodes may not be able to support the resource requirements of the Pods being rescheduled. The sizing and overall utilization of the cluster will greatly affect the behavior of the cluster and the workloads hosted there in the event of an AZ failure. Careful planning is needed to maximize the availability of the cluster even in the face of an AZ failure. There are also other considerations, like cross-AZ traffic charges, that should be taken into account. There is no &ldquo;one size fits all&rdquo; solution.</p>
<p>I hope this post is helpful. If you have questions, please do reach out to me on <a href="https://kubernetes.slack.com/">the Kubernetes Slack instance</a> (I hang out a lot in the <code>#kubeadm</code> and <code>#cluster-api-aws</code> channels), or reach out to <a href="https://twitter.com/scott_lowe">me on Twitter</a>. I&rsquo;d love to hear from you, and possibly help you if I can.</p>

  <h3>Metadata and Navigation</h3>
  <span class="post-meta">
  <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/kubernetes">Kubernetes</a> <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/aws">AWS</a> <i class="fa fa-tag" aria-hidden="true"></i>&#160;<a href="/tags/capi">CAPI</a> 

  <br />
  <i class="fa fa-arrow-circle-left" aria-hidden="true"></i> Previous Post: <a href="https://www.howellyang.com/2020/03/20/technology-short-take-125/">Technology Short Take 125</a>
  
  <br />
   <i class="fa fa-arrow-circle-right" aria-hidden="true"></i> Next Post: <a href="https://www.howellyang.com/2020/04/02/setting-up-etcd-with-kubeadm-containerd-edition/">Setting up etcd with Kubeadm, containerd Edition</a>
  </span>

  <span class="post-sharing">
  <p>Be social and share this post!<br />

  <a href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fwww.howellyang.com%2f2020%2f03%2f26%2fha-kubernetes-clusters-on-aws-with-cluster-api-v1alpha3%2f" title="Share on Facebook"><i class="fa fa-facebook-square fa-2x"></i></a>
  <a href="https://twitter.com/intent/tweet?url=https%3a%2f%2fwww.howellyang.com%2f2020%2f03%2f26%2fha-kubernetes-clusters-on-aws-with-cluster-api-v1alpha3%2f&text=HA%20Kubernetes%20Clusters%20on%20AWS%20with%20Cluster%20API%20v1alpha3" title="Share on Twitter"><i class="fa fa-twitter-square fa-2x"></i></a>
  <a href="https://plus.google.com/share?url=https%3a%2f%2fwww.howellyang.com%2f2020%2f03%2f26%2fha-kubernetes-clusters-on-aws-with-cluster-api-v1alpha3%2f" title="Share on Google Plus"><i class="fa fa-google-plus-square fa-2x"></i></a></p>
  </span>
</div>

<div class="related">
  <h3>Related Posts</h3>
  <ul class="related-posts">
  <li><a href="/2020/03/05/ha-kubernetes-clusters-on-aws-with-cluster-api-v1alpha2/">HA Kubernetes Clusters on AWS with Cluster API v1alpha2</a> <span class="post-date-list">59 May 5055</span></li><li><a href="/2019/09/26/exploring-cluster-api-v1alpha2-manifests/">Exploring Cluster API v1alpha2 Manifests</a> <span class="post-date-list">269 May 262626</span></li><li><a href="/2019/09/09/consuming-preexisting-aws-infrastructure-with-cluster-api/">Consuming Pre-Existing AWS Infrastructure with Cluster API</a> <span class="post-date-list">99 May 9099</span></li>
  </ul>
</div>      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

  </body>
</html>
